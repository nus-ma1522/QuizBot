## Checkpoint Eigenvalues and Eigenvectorsnode MarkdownToJs.js chx-y.md

### plain

Welcome back! Before we talk about eigenvalues and eigenvectors, letâ€™s quickly revisit some important concepts that will help us understand them better. Namely, matrix multiplication and null spaces.

### mcq

What does the equation $\mathbf{A}\mathbf{x} = \mathbf{b}$ represent?

- A linear combination of the rows of $\mathbf{A}$ that gives $\mathbf{b}$

* A linear combination of the columns of $\mathbf{A}$ that gives $\mathbf{b}$

- Finding the determinant of A

### plain

When we multiply a matrix $\mathbf{A}$ by a vector $\mathbf{x}$, what weâ€™re really doing is taking a **linear combination of the columns** of $\mathbf{A}$ using the entries of $\mathbf{x}$ as weights.

$$
\mathbf{A}\mathbf{x} = x_1\mathbf{a}_1 + x_2\mathbf{a}_2 + \dots + x_n\mathbf{a}_n
$$

So, $\mathbf{A}\mathbf{x} = \mathbf{b}$ means that we are expressing the vector $\mathbf{b}$ as a linear combination of the columns of $\mathbf{A}$!

### mcq

Now what about this?
$\mathbf{A}\mathbf{x} = \mathbf{0}$ represents which subspace?

- The column space of $\mathbf{A}$
- The row space of $\mathbf{A}$
- The null space of $\mathbf{A^T}$

* The null space of $\mathbf{A}$

### plain

The null space of $\mathbf{A}$! The null space of $\mathbf{A}$ consists of all vectors $\mathbf{x}$ that, when we take a linear combination of the columns of $\mathbf{A}$ using $\mathbf{x}$ as weights, give the $0$ vector.

### mcq

And if $\mathbf{A}\mathbf{x} = \mathbf{0}$ has a non-trivial solution, and that $\mathbf{A}$ is a square matrix, what does it mean about $\mathbf{A}$?

- The columns of $\mathbf{A}$ are linearly dependent

* The columns of $\mathbf{A}$ are linearly independent

- $\mathbf{A}$ is singular

* $\mathbf{A}$ is invertible

### plain

Since $\mathbf{Ax}$ simply represents a linear combination of the columns of A, if there is a non-trivial solution, we know that the columns of $\mathbf{A}$ are linearly dependent!

This also means $\mathbf{A}$ is singular!

---

### plain

Awesome! With that recap out of the way, letâ€™s dive into **eigenvectors and eigenvalues**.

### embed

https://www.geogebra.org/calculator/xvjfzk55?embed

### plain

Open the geogebra applet and slide the $\mathbf{a}$ and $\mathbf{b}$ values of vector $\mathbf{u}$ around.

Notice that for each vector $\mathbf{u}$, we premultiply it by $\mathbf{A}$ and we get a corresponding output $\mathbf{A}\mathbf{u}$. We call this a **linear transformation** of vector $\mathbf{u}$ to the resulting vector $\mathbf{Au}$.

### dialogue

Now, set $\mathbf{a} = 1$ and $\mathbf{b} = 0$. What do you realise about the vectors $\mathbf{u}$ and $\mathbf{Au}$?

- They are parallel!
- Length of $\mathbf{Au} =$ $3 \space \times\space$Length of $\mathbf{u}$

### plain

Both are correct! Premultiplying by $\mathbf{A}$ doesnâ€™t change the **direction** of $\mathbf{u}$!
We call this vector $\mathbf{u}$, an **eigenvector**!
Not only that, since the length of the resulting vector is 3 times that of the original vector, we call this special number 3, an **eigenvalue**!

### plain

Since the two vectors are parallel and that one vector is a scalar multiple of the other, I can simply write it as $\mathbf{A}\mathbf{u}$ = $\lambda \mathbf{u}$, where $\lambda$ is my scalar multiple.

### mcq

Letâ€™s try to find a simple example of $\mathbf{u}$ that always satisfies $\mathbf{A}\mathbf{u} = \lambda \mathbf{u}$.

Which vector always satisfy this equation?

- $\mathbf{u} = \mathbf{0}$

* Not enough information to conclude.

### plain

$\mathbf{u} = \mathbf{0}$ always satisfy the equation! But that's not interesting...
Thatâ€™s because it works for **any** $\lambda$, giving us infinitely many eigenvalues with no meaningful information.

So we **exclude** the zero vector and only consider **non-zero** eigenvectors.

### plain

Now, we are ready to introduce the formal definition of **eigenvalues** and **eigenvectors**.

### tex

Let A be a **square** matrix of order $n$.
A real number $\lambda$ is an **eigenvalue** of $\mathbf{A}$ if there is a **nonzero** vector $\mathbf{v}$ in $\mathbb{R}^n$, such that

$$
\mathbf{A}\mathbf{v} = \lambda \mathbf{v}.$$ In this case, $\mathbf{v}$ is called an **eigenvector** associated with $\lambda$.


### plain

Now, how do we actually **find** $\lambda$ and $\mathbf{v}$?
Letâ€™s start with $\mathbf{A}\mathbf{v} = \lambda \mathbf{v}$ and manipulate it.

### mcq

If $\mathbf{A}\mathbf{v} = \lambda \mathbf{v}$, what should we do to bring everything to one side?

- Multiply both sides by $\lambda$
- Take the transpose
* Subtract $\mathbf{A}\mathbf{v}$ from both sides
* Subtract $\lambda\mathbf{v}$ from both sides

### plain
Both options of subtracting $\mathbf{A}\mathbf{v}$ and $\lambda\mathbf{v}$ are correct and lead you to the same outcome! In this interactive, let's choose to subtract $\mathbf{A}\mathbf{v}$ from both sides.

### mcq
Subtracting gives:
$$

\lambda \mathbf{v} - \mathbf{A}\mathbf{v} = \mathbf{0}.

$$
Now we can factor out $\mathbf{v}$. What will be my result?
- $(\lambda - \mathbf{A})\mathbf{v} = \mathbf{0}$
* $(\lambda \mathbf{I} - \mathbf{A})\mathbf{v} = \mathbf{0}$
- $(\lambda + \mathbf{A})\mathbf{v} = \mathbf{0}$
- $(\mathbf{A} - \lambda \mathbf{I})\mathbf{v} = \mathbf{0}$

### plain
Remember that $\lambda$ is a scalar and hence $(\lambda - \mathbf{A})$ does not make any sense. We can however rewrite $\lambda \mathbf{v}$ as $\lambda \mathbf{I}\mathbf{v}$ and factorising $\mathbf{v}$ yields us:
$$

(\lambda \mathbf{I} - \mathbf{A})\mathbf{v} = \mathbf{0}.

$$
Immediately, this equation should start ringing some bells!! ðŸ””ðŸ””

### mcq

What are we really solving when we write $(\lambda \mathbf{I} - \mathbf{A})\mathbf{v} = \mathbf{0}$?

* The null space of $(\lambda \mathbf{I} - \mathbf{A})$

- The column space of $\mathbf{A}$
- The row space of $\mathbf{A}$
- The column space of $\mathbf{A}^T$

### plain
We are solving for the **null space** of $(\lambda \mathbf{I} - \mathbf{A})$!
I am sure that at this point, we are all experts at finding the null space and can't wait to RREF that thing and start solving for my unknowns! But hold up, let's find a better way.

### mcq

If $(\lambda \mathbf{I} - \mathbf{A})\mathbf{v} = \mathbf{0}$ has a nonzero solution $\mathbf{v}$, what does that imply about $(\lambda \mathbf{I} - \mathbf{A})$?

* It is a singular matrix
- It is an invertible matrix
- It is a diagonal matrix
- It is an orthogonal matrix

### plain
It must be a singular matrix!
<i>(If unsure, please revisit the topic on null space and invertibility)</i>

### mcq
Therefore, which of the following must hold true?
- $\det(\lambda \mathbf{I} - \mathbf{A}) \neq 0$
- $\det(\mathbf{A}) = 0$
* $\det(\lambda \mathbf{I} - \mathbf{A}) = 0$
- $\det(\lambda \mathbf{I}) = 1$

### plain

Perfect! Thatâ€™s our key condition for finding eigenvalues.
So to find the eigenvalues of $\mathbf{A}$, we solve:
$$

\det(\lambda \mathbf{I} - \mathbf{A}) = 0.

$$


### plain

Letâ€™s try a simple example!
Suppose:
$$

\mathbf{A} =
\begin{pmatrix}
2 & 1 \\
1 & 2
\end{pmatrix}

$$

### mcq

What is $\lambda \mathbf{I} - \mathbf{A}$?
- $\begin{pmatrix} \lambda + 2 & 1 \\ 1 & \lambda + 2 \end{pmatrix}$
- $\begin{pmatrix} \lambda - 2 & 1 \\ 1 & \lambda - 2 \end{pmatrix}$
- $\begin{pmatrix} -2 & -1 \\ -1 & -2 \end{pmatrix}$
* $\begin{pmatrix} \lambda - 2 & -1 \\ -1 & \lambda - 2 \end{pmatrix}$

### mcq
Now, find the determinant of $\lambda \mathbf{I} - \mathbf{A}$.

- $(\lambda - 2)^2 + 1$
- $(\lambda - 2)^2$
* $(\lambda - 2)^2 - 1$
- $(\lambda + 2)^2 - 1$

### plain
Remember that determinant of a 2 by 2 matrix is $ad - bc$. Subbing in the values, we get $det(\lambda \mathbf{I} - \mathbf{A}) = (\lambda - 2)^2 - 1$.


### plain
Recall that to have a non-zero eigenvector $\mathbf{v}$, matrix $\lambda \mathbf{I} - \mathbf{A}$ is singular and therefore, determinant is 0.

### mcq
Setting the determinant to zero:
$$

(\lambda - 2)^2 - 1 = 0
$$What are my possible eigenvalues, $\lambda$?

- $\lambda$ = 2

* $\lambda$ = 1
* $\lambda$ = 3

- What the helly?

### plain

$\lambda = 1$ or $\lambda = 3$. These are our **eigenvalues**!
If you can't solve this quadratic equation, GGs for you bro.
Just kidding: Expanding then factorising gives you $(\lambda - 1)(\lambda - 3) = 0$.

### plain

Let me interject really quickly to throw in some definitions.

### tex

Let $\mathbf{A}$ be a square matrix of order $n$, the **characteristic polynomial** of $\mathbf{A}$, denoted as $\operatorname{char}(\mathbf{A})$, is the degree $n$ polynomial

$$
\operatorname{det}(x\mathbf{I} - \mathbf{A}).
$$

### mcq

What is the characteristic polynomial of $\mathbf{A}$?
For reference:

$$
\mathbf{A} =
\begin{pmatrix}
2 & 1 \\
1 & 2
\end{pmatrix}
$$

- $(x - 1)(x - 3)$
- $x^2 - 4x + 3$
- $(x - 2)^2 - 1$

### plain

All are correct! That's what we found earlier.

### mcq

What does it mean when I substitute $x = \lambda$, where $\lambda$ is an eigenvalue of $\mathbf{A}$ ?

- $\operatorname{char}(\mathbf{A}) = 0$

* $\operatorname{char}(\mathbf{A}) \neq 0$

### plain

It must be that $\operatorname{char}(\mathbf{A}) = \operatorname{det}(\lambda\mathbf{I} - \mathbf{A}) = 0$. This result builds on the results we found earlier, where we concluded that $(\lambda\mathbf{I} - \mathbf{A})$ must be singular for a **non-zero** $\mathbf{v}$ to exist.

### plain

One more definition!

### tex

Let $\lambda$ be an eigenvalue of $\mathbf{A}$. The **algebraic multiplicity** of $\lambda$ is the largest integer $r_\lambda$ such that

$$
\operatorname{det}(x\mathbf{I} - \mathbf{A}) = (x - \lambda)^{r_\lambda}p(x),
$$for some polynomial $p(x)$.

### mcq
If you don't understand, just look at the power of what the linear factor is raised to.
What is the algebraic multiplicity of $\lambda = 1$?
For reference:
$$\operatorname{char}(\mathbf{A}) = (x - 1)(x - 3)$$
- 0
* 1
- Idk...

### plain
$\operatorname{det}(x\mathbf{I} - \mathbf{A}) = (x - 1)(x - 3)$.
$(x-1)$ is raised to the power of 1 so algebraic multiplicity = 1.

### mcq
How about algebraic multiplicity of $\lambda = 3$?
- 0
* 1
- 2

### dialogue
Time to move on finally...
Now we have the eigenvalues! What's next?
- Time to find our eigenvectors!

### plain
Hooray! For each eigenvalue, we find its corresponding eigenvector by solving:
$$

(\lambda \mathbf{I} - \mathbf{A})\mathbf{v} = \mathbf{0}.

$$

### mcq
Ok let's first find the possible eigenvectors when $\lambda = 1$. Sub into the equation and we essentially get $(\mathbf{I} - \mathbf{A})\mathbf{v} = \mathbf{0}$.
For reference:
$$

\mathbf{A} =
\begin{pmatrix}
2 & 1 \\
1 & 2
\end{pmatrix}
$$ What's $(\mathbf{I} - \mathbf{A})$?

- $\begin{pmatrix} -1 & 1 \\ 1 & -1 \end{pmatrix}$

* $\begin{pmatrix} -1 & -1 \\ -1 & -1 \end{pmatrix}$

- $\begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix}$

### mcq

I know you can't wait to use your **beloved** RREF method to solve for v. Let's do that!

What will be my final RREF form?

- $\left(\begin{array}{cc|c}
1 & 0 & 0  \\ 0 & 1 & 0 
\end{array}\right)$

* $\left(\begin{array}{cc|c} 1 & 1 & 0  \\ 0 & 0 & 0 \end{array}\right)$

### mcq

And what will be the possible values of eigenvector $\mathbf{v}$, associated with $\lambda = 1$?

- $\text{span}\left\{
\begin{pmatrix}-1 \\ 1 \end{pmatrix}\right\}$

* $\text{span}\left\{
\begin{pmatrix}1 \\ 1 \end{pmatrix}\right\}$
* $\text{span}\left\{
\begin{pmatrix}0 \\ 1 \end{pmatrix}\right\}$
* $\text{span}\left\{
\begin{pmatrix}1 \\ 0 \end{pmatrix}\right\}$

### plain

Simply parameterise the free variable(non-pivot column) to get the answer!

### plain

So essentially, we found all the possible values of eigenvector $\mathbf{v}$, we call this the **eigenspace**!

And the dimension of this eigenspace associated with $\lambda = 1$ is called the **geometric multiplicity**! In this example, it is 1.

### mcq

From our example, the **eigenspace** is basically the null space of $(\lambda \mathbf{I} - \mathbf{A})$.

- True

* False

### plain

It is true! That is basically what we are doing the whole time: Finding the possible eigenvectors $\mathbf{v}$ in $(\lambda \mathbf{I} - \mathbf{A})\mathbf{v} = \mathbf{0}$.

### mcq

Then, what can we say about the geometric multiplicity of an eigenvalue $\lambda$?

- It is the rank of $(\lambda \mathbf{I} - \mathbf{A})$

* It is the nullity of $(\lambda \mathbf{I} - \mathbf{A})$

- It is the algebraic multiplicity of $\lambda$

### plain

It is the nullity of $(\lambda \mathbf{I} - \mathbf{A})$. Nullity is the dimension of my null space!

Let's look at the formal definition.

### tex

The eigenspace associated to an eigenvalue $\lambda$ of $\mathbf{A}$ is

$$
E_{\lambda} = \left\{ \mathbf{v} \in \mathbb{R}^n \mid \mathbf{A}\mathbf{v} = \lambda \mathbf{v} \right\}
= \operatorname{Null}(\lambda \mathbf{I} - \mathbf{A}).
$$The **geometric multiplicity** of an eigenvalue $\lambda$ is the **dimension** of its associated eigenspace,
$$

\dim(E\_{\lambda}) = \operatorname{nullity}(\lambda \mathbf{I} - \mathbf{A}).

$$

### mcq
Now that we have found the associated eigenspace for $\lambda = 1$, time to do the same for the other eigenvalue $\lambda = 3$

What is my eigenspace, $\mathbf{E_3}$? For reference:$$
\mathbf{A} =
\begin{pmatrix}
2 & 1 \\
1 & 2
\end{pmatrix}
$$

- $\mathbf{E_3} = \text{span}\left\{
\begin{pmatrix}-1 \\ 1 \end{pmatrix}\right\}$
- $\mathbf{E_3} = \text{span}\left\{
\begin{pmatrix}1 \\ 0 \end{pmatrix}\right\}$

* $\mathbf{E_3} = \text{span}\left\{
\begin{pmatrix}1 \\ 1 \end{pmatrix}\right\}$

### plain

Take the same steps as earlier, find $\operatorname{Null}(3\mathbf{I} - \mathbf{A})$.

### mcq

What is the geometric multiplicity of $\lambda = 3$?

- 0

* 1

- 2

### plain

So to recap:
When we find eigenvalues and eigenvectors, we are essentially solving $(\lambda \mathbf{I} - \mathbf{A})\mathbf{v} = 0$.
Since we exclude the trivial solution $\mathbf{v} = 0$, this means the matrix $(\lambda \mathbf{I} - \mathbf{A})$ must be **singular**.
Therefore, we use $\operatorname{det}(\lambda \mathbf{I} - \mathbf{A}) = 0$ to find our eigenvalues, and using those eigenvalues, we RREF and find our eigenspace!

### dialogue

Before we end, letâ€™s think about one special case:
What if $\lambda = 0$?

- Then $\mathbf{A}\mathbf{v} = \mathbf{0}$.

### mcq

Then, which of the following must be true?

- $\mathbf{A}$ is singular

* $\mathbf{A}$ is invertible
* $\mathbf{A}$ has full rank

- Columns of $\mathbf{A}$ are linearly dependent

* $\mathbf{A}$ is diagonal

### plain

Thatâ€™s right! Given that $\mathbf{v}$ is non-zero, $\lambda = 0$ is an eigenvalue **if and only if** $\mathbf{A}$ is **singular**.

### plain

By the contrapositive, we can say:
$\mathbf{A}$ is **invertible** if and only if **0 is not an eigenvalue**.

Letâ€™s add that to our list of equivalent statements for invertibility!

### plain

And that wraps up **Eigenvalues and Eigenvectors** ðŸŽ‰

We learned that:

- Eigenvectors stay on the same line after transformation
- Eigenvalues tell us how much they are stretched or compressed
- We find them by solving $\det(\lambda \mathbf{I} - \mathbf{A}) = 0$
- Each eigenvalueâ€™s eigenspace comes from the null space of $(\lambda \mathbf{I} - \mathbf{A})$

### plain

Well we are done with this chapter, but it would be unfair to not pay some attention to the very first example matrix $\mathbf{A} = \begin{pmatrix}
3 & 1 \\
0 & 3
\end{pmatrix}$.

### mcq

Now that we have all the required information needed, what if I tell you that I can just eyeball the eigenvalue from here? What do you think $\lambda$ is?

- $\lambda = 1$
- $\lambda = 2$

* $\lambda = 3$

- Bruh, no clue.

### plain

We can immediately see that $\lambda = 3$ must be an eigenvalue! Remember how we tried to solve for $\operatorname{det}(\lambda \mathbf{I} - \mathbf{A}) = 0$?

Another way of interpreting it is: For what values of $\lambda$ will make my matrix $(\lambda \mathbf{I} - \mathbf{A})$ singular?

That $\lambda$ must be 3 so that I can delete one of the pivot columns! Interesting right?
