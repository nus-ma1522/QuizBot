---
title: Diagonalization

---

## Diagonalization

### mcq

Before we dive into 6.2, let's have a quick revision of 6.1. Can you find eigenvalues and eigenvectors of $\mathbf{A}$, where $\mathbf{A}=\left(\begin{array}{c c c} 3&1&-1\\1&3&-1\\0&0&2\\\end{array}\right)$

* $\mu_1=2, \mu_2=4; \mathbf{u}_1=\left(\begin{array}{c}1\\0\\1\\\end{array}\right), \mathbf{u}_2=\left(\begin{array}{c}0\\1\\1\\\end{array}\right), \mathbf{u}_3=\left(\begin{array}{c}1\\1\\0\\\end{array}\right)$
- Wait...what are eigenvalues and eigenvectors??

### plain

Revise 6.1 if you forgot!

### plain

So, we have 
$$
\begin{aligned}
\mathbf{A}\mathbf{u_1}=\mu_1\mathbf{u_1}, \left(\begin{array}{c c c} 3&1&-1\\1&3&-1\\0&0&2\\\end{array}\right)\left(\begin{array}{c}1\\0\\1\\\end{array}\right)=2\left(\begin{array}{c}1\\0\\1\\\end{array}\right) \\
\mathbf{A}\mathbf{u_2}=\mu_1\mathbf{u_2},
\left(\begin{array}{c c c} 3&1&-1\\1&3&-1\\0&0&2\\\end{array}\right)\left(\begin{array}{c}0\\1\\1\\\end{array}\right)=2\left(\begin{array}{c}0\\1\\1\\\end{array}\right) \\
\mathbf{A}\mathbf{u_3}=\mu_1\mathbf{u_3},\left(\begin{array}{c c c} 3&1&-1\\1&3&-1\\0&0&2\\\end{array}\right)\left(\begin{array}{c}1\\1\\0\\\end{array}\right)=4\left(\begin{array}{c}1\\1\\0\\\end{array}\right)
\end{aligned}
$$

### mcq

What's $\left(\begin{array}{c c c} 3&1&-1\\1&3&-1\\0&0&2\\\end{array}\right)\left(\begin{array}{c c c} 1&0&1\\0&1&1\\1&1&0\\\end{array}\right)$? (Hint: We stack eigenvectors of $\mathbf{A}$ together, use blockmultiplication!)

* $\left(\begin{array}{c c c} 2&0&4\\0&2&4\\2&2&0\\\end{array}\right)$
- ermmm...

### mcq

What's $\left(\begin{array}{c c c} 1&0&1\\0&1&1\\1&1&0\\\end{array}\right)\left(\begin{array}{c c c} 2&0&0\\0&2&0\\0&0&4\\\end{array}\right)$, where diagonal entries of the second matrix are eigenvalues of $\mathbf{A}$?

* $\left(\begin{array}{c c c} 2&0&4\\0&2&4\\2&2&0\\\end{array}\right)$
- hmmm...

### mcq

Wait...We are getting the same result, is this just a coincidence?

* There is something into it
- Definitely coincidence man 

### plain

Actually this is related to what we are learning today! 
:smile_cat: 

### plain

Let's say we use $\mathbf{P}$ to denote $(\mathbf{u_1}\,\mathbf{u_2}\,\dots\,\mathbf{u_n})$ of which the columns are the eigenvectors, and $\mathbf{D}$ to denote $\begin{pmatrix}
\mu_1 & 0 & \cdots & 0 \\
0 & \mu_2 & \cdots & 0 \\
\vdots & \ddots & \ddots & \vdots \\
0 & 0 & \cdots & \mu_n
\end{pmatrix}$ of which the diagonal entries are the eigenvalues. 

### dialogue

Can you prove that $\mathbf{A}\mathbf{P}=\mathbf{P}\mathbf{D}$?

* Give it a try!

### mcq

What is $\mathbf{A}\mathbf{P}$?

* $\mathbf{A}\mathbf{P}=(\mathbf{A}\mathbf{u_1}\,\mathbf{A}\mathbf{u_2}\,\dots\,\mathbf{A}\mathbf{u_n})$

### mcq

What is $\mathbf{A}\mathbf{u_1}$?
Hint: Recall $\mathbf{u_1}$ is an eigenvector!

* $\mu_1\mathbf{u_1}$
- I don't know :face_in_clouds: 

### mcq

So $(\mathbf{A}\mathbf{u_1}\,\mathbf{A}\mathbf{u_2}\,\dots\,\mathbf{A}\mathbf{u_n})=$?

* $(\mu_1\mathbf{u_1}\,\mu_2\mathbf{u_2}\,\dots\,\mu_n\mathbf{u_n})$
- Whelp :face_with_cowboy_hat: 

### mcq

What is $\mathbf{P}\mathbf{D}$？

* $(\mathbf{u_1}\,\mathbf{u_2}\,\dots\,\mathbf{u_n})\begin{pmatrix}
\mu_1 & 0 & \cdots & 0 \\
0 & \mu_2 & \cdots & 0 \\
\vdots & \ddots & \ddots & \vdots \\
0 & 0 & \cdots & \mu_n
\end{pmatrix}$

### mcq

And what will it give you?

* $(\mu_1\mathbf{u_1}\,\mu_2\mathbf{u_2}\,\dots\,\mu_n\mathbf{u_n})$

### plain

Well done! Just by observation you can see that $\mathbf{A}\mathbf{P}=\mathbf{P}\mathbf{D}$! Now let's continue with diagonalization :smiling_face_with_3_hearts: 

### mcq

What can you get from $\mathbf{A}\mathbf{P}=\mathbf{P}\mathbf{D}$, assuming that $\mathbf{P}$ is invertible?

* $\mathbf{A}=\mathbf{P}\mathbf{D}\mathbf{P}^{-1}$
* $\mathbf{P}^{-1}\mathbf{A}\mathbf{P}=\mathbf{D}$

### plain
If $\mathbf{A}$ can be expressed as $\mathbf{P}\mathbf{D}\mathbf{P}^{-1}$ or that $\mathbf{P}^{-1}\mathbf{A}\mathbf{P}$ can be expressed as a diagonal matrix $\mathbf{D}$, we say that $\mathbf{A}$ is diagonalizable!

Aha, time for the formal definition!

### tex

A square matrix $\mathbf{A}$ of order $n$ is diagonalizable if there exists an invertible matrix $\mathbf{P}$ such that $\mathbf{P}^{-1}\mathbf{A}\mathbf{P}=\mathbf{D}$ is a diagonal matrix, OR $\mathbf{A}=\mathbf{P}\mathbf{D}\mathbf{P}^{-1}$

### plain

The $\mathbf{A}$ you saw just now is diagonalizable, 
$$
\left(\begin{array}{c c c} 3&1&-1\\1&3&-1\\0&0&2\\\end{array}\right)=\left(\begin{array}{c c c} 1&0&1\\0&1&1\\1&1&0\\\end{array}\right) \left(\begin{array}{c c c} 2&0&0\\0&2&0\\0&0&4\\\end{array}\right) \left(\begin{array}{c c c} 1&0&1\\0&1&1\\1&1&0\\\end{array}\right)^{-1}
$$

<!-- ### mcq

Do you notice something from the matrices used to represent $\mathbf{A}$?

* Yes! Columns of $\left(\begin{array}{c c c} 1&0&1\\0&1&1\\1&1&0\\\end{array}\right)$ consist of eigenvectors of $\mathbf{A}$ and diagonal entries of $\left(\begin{array}{c c c} 2&0&0\\0&2&0\\0&0&4\\\end{array}\right)$ consist of eigenvalues of $\mathbf{A}$! -->

<!-- ### plain

Generalizing from this specific example, we say that $\mathbf{A}$ is diagonalizable if and only if we can find $\mathbf{P}=(\mathbf{u_1}\,\mathbf{u_2}\,\dots\,\mathbf{u_n})$, and $\mathbf{D}=\begin{pmatrix}
\mu_1 & 0 & \cdots & 0 \\
0 & \mu_2 & \cdots & 0 \\
\vdots & \ddots & \ddots & \vdots \\
0 & 0 & \cdots & \mu_n
\end{pmatrix}$ where $\mu_i$ is the eigenvalue corresponded to eigenvector $\mathbf{\mu_i}$, $i=1,\dots,n$, $\mathbf{A}\mathbf{u_i}=\mu_i\mathbf{u_i}$ such that $\mathbf{A}=\mathbf{P}\mathbf{D}\mathbf{P}^{-1}$. Note that $\mu_i$ may not be distinct. -->

<!-- ### mcq

But where does $\mathbf{P}^{-1}\mathbf{A}\mathbf{P}=\mathbf{D}$ (OR $\mathbf{A}=\mathbf{P}\mathbf{D}\mathbf{P}^{-1}$) come from at the first place?

* $\mathbf{A}\mathbf{P}=\mathbf{P}\mathbf{D}$
- I don't know :face_exhaling:  -->

<!-- ### plain

Hmm...why $\mathbf{A}\mathbf{P}=\mathbf{P}\mathbf{D}$? -->

<!-- ### mcq

What is $\mathbf{A}\mathbf{P}$?

* $\mathbf{A}\mathbf{P}=(\mathbf{A}\mathbf{u_1}\,\mathbf{A}\mathbf{u_2}\,\dots\,\mathbf{A}\mathbf{u_n})$

### mcq

What is $\mathbf{A}\mathbf{u_1}$?

* $\mu_1\mathbf{u_1}$
- I don't know :face_in_clouds: 

### mcq

So $(\mathbf{A}\mathbf{u_1}\,\mathbf{A}\mathbf{u_2}\,\dots\,\mathbf{A}\mathbf{u_n})=$?

* $(\mu_1\mathbf{u_1}\,\mu_2\mathbf{u_2}\,\dots\,\mu_n\mathbf{u_n})$
- Whelp :face_with_cowboy_hat: 

### mcq

What is $\mathbf{P}\mathbf{D}$？

* $(\mathbf{u_1}\,\mathbf{u_2}\,\dots\,\mathbf{u_n})\begin{pmatrix}
\mu_1 & 0 & \cdots & 0 \\
0 & \mu_2 & \cdots & 0 \\
\vdots & \ddots & \ddots & \vdots \\
0 & 0 & \cdots & \mu_n
\end{pmatrix}$

### mcq

And what will it give you?

* $(\mu_1\mathbf{u_1}\,\mu_2\mathbf{u_2}\,\dots\,\mu_n\mathbf{u_n})$

### plain
Congrats! You just proved $\mathbf{A}\mathbf{P}=\mathbf{P}\mathbf{D}$ by using knowledge you learned from 6.1! Now let's continue with diagonalization :smiling_face_with_3_hearts:  -->

### mcq
Wait... did you notice that we made a very convenient assumption?

* We assumed that $\mathbf{P}$ is invertible
- Hmm everything looks correct to me

### mcq

Yes! Under what condition will $\mathbf{P}$ be invertible? 

* $\mathbf{P}$ must be square
- $\mathbf{P}$ must be symmetric
* Columns of $\mathbf{P}$ are linearly independent
- $\mathbf{P}$ must be orthogonal

### plain
Exactly! For $\mathbf{P}$ to be invertible, $\mathbf{A}$ has to contain $n$ linearly independent eigenvectors! 

And if $\mathbf{P}$ is invertible, I can then say that $\mathbf{A}=\mathbf{P}\mathbf{D}\mathbf{P}^{-1}$, and $\mathbf{A}$ is diagonalizable! 


### tex

$$\textbf{Diagonalizability} \\ $$

A $n \times n$ square matrix $\mathbf{A}$ is diagonalizable if and only if $\mathbf{A}$ has $n$ linearly independent eigenvectors.

### mcq

Quick quiz! What can we say about the set consisting of all eigenvectors  $\{\mathbf{u_1},\mathbf{u_2},\dots,\mathbf{u_n}\}$?

* It forms a basis for $\mathbb{R}^n$
- No conclusion

### mcq

Test yourself! Which of the following matrices is/are diagonalizable?

- $\left(\begin{array}{c c} 0&1\\0&0\\\end{array}\right)$
* $\left(\begin{array}{c c} 3&0\\0&5\\\end{array}\right)$
- $\left(\begin{array}{c c} 2&-1\\1&0\\\end{array}\right)$

### mcq
Why are the two matrices not diagonalizable? (Hint: look at their algebraic multiplicity and geometric multiplicity)

* algebraic multiplicity $>$ geometric multiplicity
- is algebraic and geometric multiplicity calculas

### plain
If geometric multiplicity $<$ algebraic multiplicity, we won't have enough linearly independent vectors for that eigenvalue, which means columns of $\mathbf{P}$ are not linearly independent and it is not invertible, so $\mathbf{A}$ in this case is not diagonalizable. 

### mcq
For a $n \times n$ matrix $\mathbf{A}$, if it has $n$ distinct eigenvalues, is it diagonalizable?

* Yes
- Maybe not

### plain

Suppose $\lambda_1$ and $\lambda_2$ are distinct eigenvalues. Let $\mathbf{v_1}$ be an eigenvecotor associated to eigenvalue $\lambda_1$. Since $\lambda_1 \neq \lambda_2$, $\mathbf{A}\mathbf{v_1}=\lambda_1\mathbf{v_1}\neq\lambda_2\mathbf{v_1}$, so $\mathbf{v_1}$ cannot be in the eigenspace associated to $\lambda_2$, we can say that vectors from different eigenspaces (associated with different eigenvalues) are linearly independent. 

### plain

Therefore, with $n$ distinct eigenvalues, we have $n$ linearly independent eigenvectors, so we can conclude that $\mathbf{A}$ is diagonalizable. 


### plain

That's the end of 6.2! If you are interested in the proof for any theorem, please refer to notes and appendix (at the end of each chapter notes) See you in 6.3! :smile: 







